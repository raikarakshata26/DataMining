{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01488c9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import operator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6e77d",
   "metadata": {},
   "source": [
    "### I have downloaded the complete dataset from Kaggle: https://www.kaggle.com/datasets/ulrikthygepedersen/rotten-tomatoes-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "140d6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref.: https://stackoverflow.com/questions/5552555/unicodedecodeerror-invalid-continuation-byte\n",
    "df = pd.read_csv(\"Downloads/rt_reviews.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ed67f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rotten</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rotten</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rotten</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Freshness                                             Review\n",
       "0     fresh   Manakamana doesn't answer any questions, yet ...\n",
       "1     fresh   Wilfully offensive and powered by a chest-thu...\n",
       "2    rotten   It would be difficult to imagine material mor...\n",
       "3    rotten   Despite the gusto its star brings to the role...\n",
       "4    rotten   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A peek at the Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "839a346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews:  480000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Reviews: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cae44bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any null values?\n",
      "Freshness :  number of null values= 0\n",
      "Review :  number of null values= 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Are there any null values?\")\n",
    "for column in df.columns:\n",
    "    print(column, \":  number of null values=\", df[column].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9ce72",
   "metadata": {},
   "source": [
    "### Divide the dataset as train, development, and test.\n",
    "- Please note that the dataset size is huge.\n",
    "- To avoid computational resource constrainings, I am considering 20% of the entire dataset for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "325bcbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Training and Test Sets\n",
    "# As the dataset is large I am selecting 20% reviews to train, dev and test the model.\n",
    "\n",
    "df1, df2 = train_test_split(df, stratify=df[\"Freshness\"], test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b0d9d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df1 DataFrame:  (96000, 2)\n"
     ]
    }
   ],
   "source": [
    "# I will be developing the model and testing it with df1 data only.\n",
    "\n",
    "print(\"Number of rows in df1 DataFrame: \", df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c96b988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rotten    48000\n",
       "fresh     48000\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distrutbution of Freshness column\n",
    "df1[\"Freshness\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f4016582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "72ac8bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rotten</td>\n",
       "      <td>Drive a stake through the heart of this stink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh</td>\n",
       "      <td>A political drama that assumes you'll be able...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rotten</td>\n",
       "      <td>How about next time, instead of telling us ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Perhaps the most salient and unsung thread in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fresh</td>\n",
       "      <td>This battle of the voices [Steve Coogan and R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95995</th>\n",
       "      <td>rotten</td>\n",
       "      <td>As Cuarï¿½ï¿½n spells out in his int\"Life in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95996</th>\n",
       "      <td>fresh</td>\n",
       "      <td>This is just the movie for two hours of mindl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95997</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Certainly an enjoyable experiment, but ultima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95998</th>\n",
       "      <td>rotten</td>\n",
       "      <td>Again and again, the I Love Trouble script ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95999</th>\n",
       "      <td>fresh</td>\n",
       "      <td>click to read the full review at Movies for t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Freshness                                             Review\n",
       "0        rotten   Drive a stake through the heart of this stink...\n",
       "1         fresh   A political drama that assumes you'll be able...\n",
       "2        rotten   How about next time, instead of telling us ho...\n",
       "3         fresh   Perhaps the most salient and unsung thread in...\n",
       "4         fresh   This battle of the voices [Steve Coogan and R...\n",
       "...         ...                                                ...\n",
       "95995    rotten   As Cuarï¿½ï¿½n spells out in his int\"Life in ...\n",
       "95996     fresh   This is just the movie for two hours of mindl...\n",
       "95997     fresh   Certainly an enjoyable experiment, but ultima...\n",
       "95998    rotten   Again and again, the I Love Trouble script ta...\n",
       "95999     fresh   click to read the full review at Movies for t...\n",
       "\n",
       "[96000 rows x 2 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bbe3ff",
   "metadata": {},
   "source": [
    "#### Splitting the Dataset into Train and Test: 80-20 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "abe6bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Train Test Split\n",
    "train_df, test_df = train_test_split(df1, stratify=df1[\"Freshness\"], test_size=0.2)\n",
    "\n",
    "# Resetting the indices.\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690303b0",
   "metadata": {},
   "source": [
    "#### Splitting the Train Dataset into Train and Dev: 80-20 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a36eebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Train Dev Split\n",
    "train_df, dev_df = train_test_split(train_df, stratify=train_df[\"Freshness\"], test_size=0.2)\n",
    "\n",
    "# Resetting the indices.\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "dev_df = dev_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "048b0fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataSize:  61440\n",
      "Dev DataSize:  15360\n",
      "Testing DataSize:  19200\n"
     ]
    }
   ],
   "source": [
    "print(\"Training DataSize: \", train_df.shape[0])\n",
    "print(\"Dev DataSize: \", dev_df.shape[0])\n",
    "print(\"Testing DataSize: \", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1046f4",
   "metadata": {},
   "source": [
    "#### Preprocessing the Train, Dev and Test Set Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c3f0bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_review(review):\n",
    "    # Stripping leading and trailing empty space characters\n",
    "    # Converting the text to lower case letters\n",
    "    review = review.strip().lower().split()\n",
    "    \n",
    "    # Removing stopwords\n",
    "    review = \" \".join([word for word in review if word not in stop_words])\n",
    "    \n",
    "    # Selecting only word with alphabet characters\n",
    "    review = re.findall(r'[a-z]+', review)\n",
    "    \n",
    "    # Stemming the words and including a word if it has more than two characters\n",
    "    review = [ps.stem(word) for word in review if len(ps.stem(word)) > 2]\n",
    "    \n",
    "    # Returning the list of words\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb8d3e",
   "metadata": {},
   "source": [
    "##### Train Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ece97ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"preprocessed_review\"] = train_df[\"Review\"].apply(preprocess_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151e619",
   "metadata": {},
   "source": [
    "##### Dev Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a737a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df[\"preprocessed_review\"] = dev_df[\"Review\"].apply(preprocess_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a7bb0",
   "metadata": {},
   "source": [
    "##### Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "13e7ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"preprocessed_review\"] = test_df[\"Review\"].apply(preprocess_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71b2e5",
   "metadata": {},
   "source": [
    "#### Building Vocabulary List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a880d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61440/61440 [00:49<00:00, 1245.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of words in vocabulary list:  29037\n"
     ]
    }
   ],
   "source": [
    "all_reviews_string = \"\"\n",
    "\n",
    "\n",
    "# Iterating through all the samples in the training DataFrame\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    \n",
    "    # Retrieve the review\n",
    "    review = train_df.loc[i, \"preprocessed_review\"]\n",
    "    \n",
    "    all_reviews_string = all_reviews_string + \" \" + \" \".join(review)\n",
    "    \n",
    "    \n",
    "vocabulary_list = list(set(all_reviews_string.split()))\n",
    "print(\"Total Number of words in vocabulary list: \", len(vocabulary_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a9e0e",
   "metadata": {},
   "source": [
    "##### Omitting rare words if the occurrence is less than five times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a6061211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of words in Vocabulary List after removing Rare Words:  17748\n"
     ]
    }
   ],
   "source": [
    "vocab_count = {}\n",
    "\n",
    "for word in all_reviews_string.split():\n",
    "    if word not in vocab_count.keys():\n",
    "        vocab_count[word] = 1\n",
    "    else:\n",
    "        vocab_count[word] += 1\n",
    "        \n",
    "vocab_count = {k:v for k, v in vocab_count.items() if v<5}\n",
    "\n",
    "print(\"Total Number of words in Vocabulary List after removing Rare Words: \", len(vocab_count.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f4082",
   "metadata": {},
   "source": [
    "#### Calculate the following probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24e9e2",
   "metadata": {},
   "source": [
    "##### Probability of the Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b97f5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total review documents in the training set\n",
    "total_reviews = len(train_df)\n",
    "\n",
    "# Computing the probability of occurrence of each word across all the documents\n",
    "prob_of_occurrence = {k:v/total_reviews for k, v in vocab_count.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7c7ed",
   "metadata": {},
   "source": [
    "##### Conditional Probability of the Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8e1b844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17748/17748 [06:09<00:00, 48.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to keep track of the words that appear in \"fresh\" class and their probabilities\n",
    "fresh_class_words = {}\n",
    "\n",
    "fresh_df = train_df[train_df[\"Freshness\"]==\"fresh\"]\n",
    "for word in tqdm(vocab_count.keys()):\n",
    "    mask = fresh_df[\"preprocessed_review\"].apply(lambda x: True if word in x else False)\n",
    "    if sum(mask) > 0:\n",
    "        fresh_class_words[word] = sum(mask)/len(fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8ec2cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17748/17748 [06:05<00:00, 48.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to keep track of the words that appear in \"rotten\" class and their probabilities\n",
    "rotten_class_words = {}\n",
    "\n",
    "rotten_df = train_df[train_df[\"Freshness\"]==\"rotten\"]\n",
    "for word in tqdm(vocab_count.keys()):\n",
    "    mask = rotten_df[\"preprocessed_review\"].apply(lambda x: True if word in x else False)\n",
    "    if sum(mask) > 0:\n",
    "        rotten_class_words[word] = sum(mask)/len(rotten_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d29c6",
   "metadata": {},
   "source": [
    "##### Computing Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "63f277f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Dirstirbution Counts:  {'rotten': 30720, 'fresh': 30720}\n",
      "Class-wise Probability Distributions\n",
      "Class= rotten  Probability= 0.5\n",
      "Class= fresh  Probability= 0.5\n",
      "\n",
      "\n",
      "Probabilities after applying Log Transformations\n",
      "Class= rotten, Probability=  -0.6931471805599453\n",
      "Class= fresh, Probability=  -0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "data_distribution = dict(train_df[\"Freshness\"].value_counts())\n",
    "\n",
    "print(\"Training Class Dirstirbution Counts: \", data_distribution)\n",
    "\n",
    "# Storing the total number of reviews in a variable\n",
    "total_samples = train_df.shape[0]\n",
    "\n",
    "# Computing the Class Probabilities\n",
    "class_probabilities = {k:(v/total_samples) for k, v in data_distribution.items()}\n",
    "\n",
    "print(\"Class-wise Probability Distributions\")\n",
    "for key, value in class_probabilities.items():\n",
    "    print(\"Class=\", key, \" Probability=\", value)\n",
    "    \n",
    "    \n",
    "# Computing the Log of Class-wise probabilities\n",
    "fresh_prob = math.log(class_probabilities[\"fresh\"])\n",
    "rotten_prob = math.log(class_probabilities[\"rotten\"])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Probabilities after applying Log Transformations\")\n",
    "print(\"Class= rotten, Probability= \", rotten_prob)\n",
    "print(\"Class= fresh, Probability= \", fresh_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef9489",
   "metadata": {},
   "source": [
    "#### Calculate accuracy using dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "aed76f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15360/15360 [00:00<00:00, 195985.38it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "\n",
    "# Iterating through each of the dev set reviews.\n",
    "for review in tqdm(dev_df[\"preprocessed_review\"]):\n",
    "        \n",
    "    # Initializing the prob_fresh and prob_rotten with the class probabilities.\n",
    "    prob_fresh = fresh_prob\n",
    "    prob_rotten = rotten_prob\n",
    "    \n",
    "    # Iterating through each word in the review.\n",
    "    for word in review:\n",
    "        \n",
    "        # If the word is in fresh class words...\n",
    "        if word in fresh_class_words.keys():\n",
    "            prob_fresh += math.log(fresh_class_words[word])\n",
    "            \n",
    "        # If the word is in rotten class words..    \n",
    "        elif word in rotten_class_words.keys():\n",
    "            prob_rotten += math.log(rotten_class_words[word])\n",
    "            \n",
    "    # If the probability of belonging to fresh class is greater than rotten class probability, assign it to fresh class.\n",
    "    if prob_fresh > prob_rotten:\n",
    "        y_pred.append(\"fresh\")\n",
    "        \n",
    "    # Assign rotten class as target label.\n",
    "    else:\n",
    "        y_pred.append(\"rotten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1af44e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Model on the Dev Set is:  0.47194010416666665\n"
     ]
    }
   ],
   "source": [
    "count_of_correct_predictions = 0\n",
    "\n",
    "for actual_class, predicted_class in zip(dev_df[\"Freshness\"], y_pred):\n",
    "    if actual_class==predicted_class:\n",
    "        count_of_correct_predictions += 1\n",
    "\n",
    "print(\"Accuracy of the Naive Bayes Model on the Dev Set is: \", count_of_correct_predictions/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48353467",
   "metadata": {},
   "source": [
    "#### Compare the Effect of Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b6a8e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15360/15360 [00:00<00:00, 237484.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Model on the Dev Set with Laplacian Smoothing is:  0.47194010416666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "\n",
    "fresh_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in fresh_class_words.items()}\n",
    "rotten_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in rotten_class_words.items()}\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# Iterating through each of the dev set reviews.\n",
    "for review in tqdm(dev_df[\"preprocessed_review\"]):\n",
    "    \n",
    "    # Initializing the prob_fresh and prob_rotten with the class probabilities.\n",
    "    prob_fresh = fresh_prob\n",
    "    prob_rotten = rotten_prob\n",
    "    \n",
    "    # Iterating through each word in the review.\n",
    "    for word in review:\n",
    "        \n",
    "        # If the word is in fresh class words...\n",
    "        if word in fresh_class_words2.keys():\n",
    "            prob_fresh += math.log(fresh_class_words2[word])\n",
    "            \n",
    "        # If the word is in rotten class words..    \n",
    "        elif word in rotten_class_words2.keys():\n",
    "            prob_rotten += math.log(rotten_class_words2[word])\n",
    "            \n",
    "    # If the probability of belonging to fresh class is greater than rotten class probability, assign it to fresh class.\n",
    "    if prob_fresh > prob_rotten:\n",
    "        y_pred.append(\"fresh\")\n",
    "        \n",
    "    # Assign rotten class as target label.\n",
    "    else:\n",
    "        y_pred.append(\"rotten\")\n",
    "        \n",
    "\n",
    "count_of_correct_predictions = 0\n",
    "\n",
    "for actual_class, predicted_class in zip(dev_df[\"Freshness\"], y_pred):\n",
    "    if actual_class==predicted_class:\n",
    "        count_of_correct_predictions += 1\n",
    "\n",
    "print(\"Accuracy of the Naive Bayes Model on the Dev Set with Laplacian Smoothing is: \", count_of_correct_predictions/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b48f05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15360/15360 [00:00<00:00, 233104.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Model on the Dev Set with Laplacian Smoothing is:  0.47194010416666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 100\n",
    "\n",
    "fresh_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in fresh_class_words.items()}\n",
    "rotten_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in rotten_class_words.items()}\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# Iterating through each of the dev set reviews.\n",
    "for review in tqdm(dev_df[\"preprocessed_review\"]):\n",
    "    \n",
    "    # Initializing the prob_fresh and prob_rotten with the class probabilities.\n",
    "    prob_fresh = fresh_prob\n",
    "    prob_rotten = rotten_prob\n",
    "    \n",
    "    # Iterating through each word in the review.\n",
    "    for word in review:\n",
    "        \n",
    "        # If the word is in fresh class words...\n",
    "        if word in fresh_class_words2.keys():\n",
    "            prob_fresh += math.log(fresh_class_words2[word])\n",
    "            \n",
    "        # If the word is in rotten class words..    \n",
    "        elif word in rotten_class_words2.keys():\n",
    "            prob_rotten += math.log(rotten_class_words2[word])\n",
    "            \n",
    "    # If the probability of belonging to fresh class is greater than rotten class probability, assign it to fresh class.\n",
    "    if prob_fresh > prob_rotten:\n",
    "        y_pred.append(\"fresh\")\n",
    "        \n",
    "    # Assign rotten class as target label.\n",
    "    else:\n",
    "        y_pred.append(\"rotten\")\n",
    "        \n",
    "\n",
    "count_of_correct_predictions = 0\n",
    "\n",
    "for actual_class, predicted_class in zip(dev_df[\"Freshness\"], y_pred):\n",
    "    if actual_class==predicted_class:\n",
    "        count_of_correct_predictions += 1\n",
    "\n",
    "print(\"Accuracy of the Naive Bayes Model on the Dev Set with Laplacian Smoothing is: \", count_of_correct_predictions/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b0be373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15360/15360 [00:00<00:00, 231875.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Model on the Dev Set with Laplacian Smoothing is:  0.47194010416666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 1000\n",
    "\n",
    "fresh_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in fresh_class_words.items()}\n",
    "rotten_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in rotten_class_words.items()}\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# Iterating through each of the dev set reviews.\n",
    "for review in tqdm(dev_df[\"preprocessed_review\"]):\n",
    "    \n",
    "    # Initializing the prob_fresh and prob_rotten with the class probabilities.\n",
    "    prob_fresh = fresh_prob\n",
    "    prob_rotten = rotten_prob\n",
    "    \n",
    "    # Iterating through each word in the review.\n",
    "    for word in review:\n",
    "        \n",
    "        # If the word is in fresh class words...\n",
    "        if word in fresh_class_words2.keys():\n",
    "            prob_fresh += math.log(fresh_class_words2[word])\n",
    "            \n",
    "        # If the word is in rotten class words..    \n",
    "        elif word in rotten_class_words2.keys():\n",
    "            prob_rotten += math.log(rotten_class_words2[word])\n",
    "            \n",
    "    # If the probability of belonging to fresh class is greater than rotten class probability, assign it to fresh class.\n",
    "    if prob_fresh > prob_rotten:\n",
    "        y_pred.append(\"fresh\")\n",
    "        \n",
    "    # Assign rotten class as target label.\n",
    "    else:\n",
    "        y_pred.append(\"rotten\")\n",
    "        \n",
    "\n",
    "count_of_correct_predictions = 0\n",
    "\n",
    "for actual_class, predicted_class in zip(dev_df[\"Freshness\"], y_pred):\n",
    "    if actual_class==predicted_class:\n",
    "        count_of_correct_predictions += 1\n",
    "\n",
    "print(\"Accuracy of the Naive Bayes Model on the Dev Set with Laplacian Smoothing is: \", count_of_correct_predictions/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc25d0d",
   "metadata": {},
   "source": [
    "##### Top 10 words that predicts each class - without Laplacian Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5c1cc652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burli 0.00013020833333333333\n",
      "hardscrabbl 0.00013020833333333333\n",
      "silicon 0.00013020833333333333\n",
      "whoa 0.00013020833333333333\n",
      "paparazzi 0.00013020833333333333\n",
      "chad 0.00013020833333333333\n",
      "rousingli 0.00013020833333333333\n",
      "havana 0.00013020833333333333\n",
      "colman 0.00013020833333333333\n",
      "ennobl 0.00013020833333333333\n"
     ]
    }
   ],
   "source": [
    "# Printing top-10 words in the fresh_class_words\n",
    "sorted_fcw = dict(sorted(fresh_class_words.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "# top-10 most probable words \"fresh\" class and their probabilities\n",
    "for word in list(sorted_fcw.keys())[:10]:\n",
    "    print(word, sorted_fcw[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "94b70fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bangkok 0.00013020833333333333\n",
      "sox 0.00013020833333333333\n",
      "ter 0.00013020833333333333\n",
      "grime 0.00013020833333333333\n",
      "objectif 0.00013020833333333333\n",
      "marmaduk 0.00013020833333333333\n",
      "hoser 0.00013020833333333333\n",
      "diretor 0.00013020833333333333\n",
      "oldi 0.00013020833333333333\n",
      "pretext 0.00013020833333333333\n"
     ]
    }
   ],
   "source": [
    "# Printing top-10 words in the rotten_class_words\n",
    "sorted_rcw = dict(sorted(rotten_class_words.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "# top-10 most probable words \"rotten\" class and their probabilities\n",
    "for word in list(sorted_rcw.keys())[:10]:\n",
    "    print(word, sorted_rcw[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc97ba8",
   "metadata": {},
   "source": [
    "#### Using the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "89866648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19200/19200 [00:00<00:00, 200183.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Model on the Test Set with Laplacian Smoothing is:  0.4742708333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "\n",
    "fresh_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in fresh_class_words.items()}\n",
    "rotten_class_words2 = {k:(v+alpha)/(total_samples + alpha*len(vocab_count.keys())) for k, v in rotten_class_words.items()}\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# Iterating through each of the test set reviews.\n",
    "for review in tqdm(test_df[\"preprocessed_review\"]):\n",
    "    \n",
    "    # Initializing the prob_fresh and prob_rotten with the class probabilities.\n",
    "    prob_fresh = fresh_prob\n",
    "    prob_rotten = rotten_prob\n",
    "    \n",
    "    # Iterating through each word in the review.\n",
    "    for word in review:\n",
    "        \n",
    "        # If the word is in fresh class words...\n",
    "        if word in fresh_class_words2.keys():\n",
    "            prob_fresh += math.log(fresh_class_words2[word])\n",
    "            \n",
    "        # If the word is in rotten class words..    \n",
    "        elif word in rotten_class_words2.keys():\n",
    "            prob_rotten += math.log(rotten_class_words2[word])\n",
    "            \n",
    "    # If the probability of belonging to fresh class is greater than rotten class probability, assign it to fresh class.\n",
    "    if prob_fresh > prob_rotten:\n",
    "        y_pred.append(\"fresh\")\n",
    "        \n",
    "    # Assign rotten class as target label.\n",
    "    else:\n",
    "        y_pred.append(\"rotten\")\n",
    "        \n",
    "\n",
    "count_of_correct_predictions = 0\n",
    "\n",
    "for actual_class, predicted_class in zip(test_df[\"Freshness\"], y_pred):\n",
    "    if actual_class==predicted_class:\n",
    "        count_of_correct_predictions += 1\n",
    "\n",
    "print(\"Accuracy of the Naive Bayes Model on the Test Set with Laplacian Smoothing is: \", count_of_correct_predictions/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d2339",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece\n",
    "2. https://www.kaggle.com/datasets/ulrikthygepedersen/rotten-tomatoes-reviews\n",
    "3. https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "4. https://www.geeksforgeeks.org/python-stemming-words-with-nltk/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
